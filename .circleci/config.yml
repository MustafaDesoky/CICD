# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

orbs:
  aws-cli: circleci/aws-cli@3.1.4
# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
commands:
  destroy_infra:
    steps:
      - run :
         name: destroy infra on fail 
         when: on_fail
         command: |
              aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
jobs:
  #.create_infrastructure: 
      #docker:
      #  - image: amazon/aws-cli
     # steps:
        #- checkout
       # - run:
         #   name: Create Cloudformation Stack
        #    command: |
       #       aws cloudformation deploy \
      #          --template-file ./ec2.yml \
     #           --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
    #            --region us-east-1
  configure_infra:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: circleci/python:3.8
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - add_ssh_keys:
          # You can get this ID in the section where you registered the SSH Key
          fingerprints: ["cc:29:48:71:ad:59:58:1e:86:a6:a2:dd:5f:d0:82:8f"]
      - run:
          name: Install Ansible
          command: |
            pip install ansible
      - run:
          name: run Ansible
          command: |
            ansible-playbook -i inventory.txt main.yml
            
  smoke_test:
    docker:
      - image: amazon/aws-cli
    steps:  
    - checkout
    - run:
        name: doing smoke test using CURL
        command: |
         URL="https://blog.udacity.com/"  
         # test if website exist
         if curl -s --head ${URL}
         then
            return 1
          else
            return 1
          fi
    - destroy_infra   

  create_infrastructure:
    docker: 
      - image: amazon/aws-cli
    steps:
    - checkout
    - run:
        command: |     
          S3_BUCKET_NAME="mybucket2970808"
          aws cloudformation deploy \
          --template-file cloudfront.yml \
          --stack-name production-distro \
          --parameter-overrides PipelineID="${S3_BUCKET_NAME}" \ # Name of the S3 bucket you created manually.
          --tags project=udapeople &   

  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
              aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}" 
        #CIRCLE_WORKFLOW_ID:0:7to help form the name of our new bucket. This helps us to reference the bucket later, in another job/command.
        # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete  

  get_last_deployment_id:
    docker:
    - image: amazon/aws-cli
    steps:
    - checkout
    #performs the query and saves the id to a file that we can persist to the workspace. 
    - run: yum install -y tar gzip
    - run: 
        command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
    - persist_to_workspace:
        root: ~/
        paths:
        - textfile.txt

  promote_to_production:
    #that executes our cloudfront.yml CloudFormation template used in the manual steps.
    docker: 
    - image: amazon/aws-cli
    steps:
    - checkout
    - run:
        name: Execute cloudfront.yml
        command: |
          aws cloudformation deploy \
          --template-file cloudfront.yml \
          --stack-name production-distro \
          --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  clean_up_old_front_end:
  #uses the pipeline ID to destroy the previous production version's S3 bucket and CloudFormation stack. To achieve this, you need to retrieve from the workspace the file where the previous Pipeline ID was stored. Once you have the Pipeline ID              
    docker:
      - image: amazon/aws-cli
    steps:
    - checkout
    - run: yum install -y tar gzip
    - attach_workspace:
        at: ~/
    - run:
        name: Destroy the previous S3 bucket and CloudFormation stack. 
        # Use $OldBucketID environment variable or mybucket644752792305 below.
        # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
        command: |
          export OldBucketID=$(cat ~/textfile.txt)
          aws s3 rm "s3://${OldBucketID}" --recursive

     

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  create_infrastructure-workflow:
    jobs:
        - create_and_deploy_front_end
        - promote_to_production:
            requires: 
              - create_and_deploy_front_end
        - get_last_deployment_id
       
